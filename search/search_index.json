{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Hey # You will find here all documentation usefull for when Jeremie will leave. Enjoy.","title":"Home"},{"location":"#hey","text":"You will find here all documentation usefull for when Jeremie will leave. Enjoy.","title":"Hey"},{"location":"archi/api/","text":"API Gateway Architecture # This schema refers to the API Gateway module . Important consideration: add_endpoint can be called multiple time duplicating corresponding resources. In practice, a lot of those 'resources' are just made to link function, methods and the api. Each endpoint generate: One LambdaFunction One associated role One methode One log group","title":"API Gateways"},{"location":"archi/api/#api-gateway-architecture","text":"This schema refers to the API Gateway module . Important consideration: add_endpoint can be called multiple time duplicating corresponding resources. In practice, a lot of those 'resources' are just made to link function, methods and the api. Each endpoint generate: One LambdaFunction One associated role One methode One log group","title":"API Gateway Architecture"},{"location":"code/boto3/","text":"Boto3 # Boto3 is used to interact with resources on aws. It can be used to query data from databases, read logs, and even create resources. Boto3 is a wrapper that uses aws REST API. Getting started # First, you will need to install boto3 in your environement. Note that boto3 is natively available on lambda runtime. On your local machine, run pip install boto3 or conda install boto3 . Boto3 is very well documented online, simply search \"boto3 what you wan't to do \" on google and you will find documentation. Session and credentials # A boto3 Session is used to authenticate you. You can create a session using boto3.Session() . Boto3 will use default configuration to open the Session. It is a good practice to explicitly specify the region you want to intrect with in the Session: boto3.Session(region_name='ap-southeast-3') . Boto3 in Lambdas # Boto3 will inherite the lambda permission. Boto3 in local # Refere to the boto3 documentation for detailed explanation on boto3 credentials. The best practice would be to install the aws cli on you local machine and then configure profiles, access key and secret key id on the ~/./aws directory . However, you can still specify your AWS access when opening a session: session = session.Session( aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, ) Extract from boto3 docs: ACCESS_KEY, SECRET_KEY, and SESSION_TOKEN are variables that contain your access key, secret key, and optional session token. Note that the examples above do not have hard coded credentials. We do not recommend hard coding credentials in your source code . Clients # Boto3 clients are used to interact with specific AWS API, their is a lot of different client. To create one simply use: session = boto3.Session(region_name='ap-southeast-3') dynamodb_client = session.client(\"dynamodb\") timestreamwrite_client = session.client(\"timestream-write\") lambda_client = session.client(\"lambda\") ... DynamoDB Examples # Assuming you have a working boto3 client. Put item # Insert an item in a dynamo table. import boto3 session = boto3.Session(region_name='ap-southeast-3') dynamodb_client = session.client(\"dynamodb\") dynamodb_response = dynamodb_client.put_item( TableName=\"TABLE_NAME\", Item={ \"Key1\": {\"S\": \"Hello\"}, \"Key2\": {\"N\": \"2.154864584\"}, \"Key3\": {\"L\": [\"1\", \"2\", \"3\"]}, }, ) Query items # Query (different from scaning) items in dynamodb. You can use boto3 resource to abstract some of the parsing logic. import boto3 dynamodb = boto3.resource(\"dynamodb\", region_name='ap-southeast-3') table = dynamodb.Table(\"TABLE_NAME\") dynamodb_response = table.query( KeyConditionExpression=Key(\"Key\").eq(\"somethin\") & Key(\"Timestamp\").between(1, 60), ) Boto3 dom't use float but Decimals. You may wan't to build a Encoder for this. import json from decimal import Decimal class DecimalEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, Decimal): return str(obj) return json.JSONEncoder.default(self, obj) query_result = json.dumps(dynamodb_response, cls=DecimalEncoder) Timestream # There is two timestream client, timestream-write and timestream-query . Query a table # Execute a SQL query and parse the results. import boto3 import pandas session = boto3.Session(region_name=\"ap-southeast-2\") ts_query = session.client(\"timestream-query\") QUERY_1 = \"\"\" SELECT time, deviceId, measure_value::double AS temperature FROM \"ProjectTable-brewai-sensor-iaq-dev\".\"brewai_api\" WHERE measure_name='temperature' AND time between ago(1h) and now() ORDER BY time DESC \"\"\" response = ts_query.query( QueryString=QUERY_1 ) columns_name = [col['Name'] for col in response[\"ColumnInfo\"]] columns_type = [col[\"Type\"]['ScalarType'] for col in response[\"ColumnInfo\"]] rows = [row[\"Data\"] for row in response[\"Rows\"]] rows_list = [[next(iter(el.values())) for el in row] for row in rows] df = pd.DataFrame(rows_list, columns=columns_name) df.time = df.time.dt.tz_localize('UTC').dt.tz_convert('Australia/ACT')","title":"Boto3"},{"location":"code/boto3/#boto3","text":"Boto3 is used to interact with resources on aws. It can be used to query data from databases, read logs, and even create resources. Boto3 is a wrapper that uses aws REST API.","title":"Boto3"},{"location":"code/boto3/#getting-started","text":"First, you will need to install boto3 in your environement. Note that boto3 is natively available on lambda runtime. On your local machine, run pip install boto3 or conda install boto3 . Boto3 is very well documented online, simply search \"boto3 what you wan't to do \" on google and you will find documentation.","title":"Getting started"},{"location":"code/boto3/#session-and-credentials","text":"A boto3 Session is used to authenticate you. You can create a session using boto3.Session() . Boto3 will use default configuration to open the Session. It is a good practice to explicitly specify the region you want to intrect with in the Session: boto3.Session(region_name='ap-southeast-3') .","title":"Session and credentials"},{"location":"code/boto3/#boto3-in-lambdas","text":"Boto3 will inherite the lambda permission.","title":"Boto3 in Lambdas"},{"location":"code/boto3/#boto3-in-local","text":"Refere to the boto3 documentation for detailed explanation on boto3 credentials. The best practice would be to install the aws cli on you local machine and then configure profiles, access key and secret key id on the ~/./aws directory . However, you can still specify your AWS access when opening a session: session = session.Session( aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY, ) Extract from boto3 docs: ACCESS_KEY, SECRET_KEY, and SESSION_TOKEN are variables that contain your access key, secret key, and optional session token. Note that the examples above do not have hard coded credentials. We do not recommend hard coding credentials in your source code .","title":"Boto3 in local"},{"location":"code/boto3/#clients","text":"Boto3 clients are used to interact with specific AWS API, their is a lot of different client. To create one simply use: session = boto3.Session(region_name='ap-southeast-3') dynamodb_client = session.client(\"dynamodb\") timestreamwrite_client = session.client(\"timestream-write\") lambda_client = session.client(\"lambda\") ...","title":"Clients"},{"location":"code/boto3/#dynamodb-examples","text":"Assuming you have a working boto3 client.","title":"DynamoDB Examples"},{"location":"code/boto3/#put-item","text":"Insert an item in a dynamo table. import boto3 session = boto3.Session(region_name='ap-southeast-3') dynamodb_client = session.client(\"dynamodb\") dynamodb_response = dynamodb_client.put_item( TableName=\"TABLE_NAME\", Item={ \"Key1\": {\"S\": \"Hello\"}, \"Key2\": {\"N\": \"2.154864584\"}, \"Key3\": {\"L\": [\"1\", \"2\", \"3\"]}, }, )","title":"Put item"},{"location":"code/boto3/#query-items","text":"Query (different from scaning) items in dynamodb. You can use boto3 resource to abstract some of the parsing logic. import boto3 dynamodb = boto3.resource(\"dynamodb\", region_name='ap-southeast-3') table = dynamodb.Table(\"TABLE_NAME\") dynamodb_response = table.query( KeyConditionExpression=Key(\"Key\").eq(\"somethin\") & Key(\"Timestamp\").between(1, 60), ) Boto3 dom't use float but Decimals. You may wan't to build a Encoder for this. import json from decimal import Decimal class DecimalEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, Decimal): return str(obj) return json.JSONEncoder.default(self, obj) query_result = json.dumps(dynamodb_response, cls=DecimalEncoder)","title":"Query items"},{"location":"code/boto3/#timestream","text":"There is two timestream client, timestream-write and timestream-query .","title":"Timestream"},{"location":"code/boto3/#query-a-table","text":"Execute a SQL query and parse the results. import boto3 import pandas session = boto3.Session(region_name=\"ap-southeast-2\") ts_query = session.client(\"timestream-query\") QUERY_1 = \"\"\" SELECT time, deviceId, measure_value::double AS temperature FROM \"ProjectTable-brewai-sensor-iaq-dev\".\"brewai_api\" WHERE measure_name='temperature' AND time between ago(1h) and now() ORDER BY time DESC \"\"\" response = ts_query.query( QueryString=QUERY_1 ) columns_name = [col['Name'] for col in response[\"ColumnInfo\"]] columns_type = [col[\"Type\"]['ScalarType'] for col in response[\"ColumnInfo\"]] rows = [row[\"Data\"] for row in response[\"Rows\"]] rows_list = [[next(iter(el.values())) for el in row] for row in rows] df = pd.DataFrame(rows_list, columns=columns_name) df.time = df.time.dt.tz_localize('UTC').dt.tz_convert('Australia/ACT')","title":"Query a table"},{"location":"code/lambdas/","text":"Lambda Python Code Examples # You can find all the examples source code files undes 'src/code'. All examples are based on the BrewAI IAQ project. List of examples: Filename Description table_get.py Get endpoint for API Gateway that query items from dynamodb. table_put.py Put endpoint for API Gateway that insert items in dynamodb. manage_conn.py Connections manager for websocket api. msg_conn.py Message sender for websocket api. timestream_get.py Get endpoint for API Gateway that query items from timestream. timestream_put.py Put endpoint for API Gateway that upsert items on timestream. brewai_fetch.py Scheduled lambdas that retreive latest data from api and insert in our own system. make_prediction.py Lambdas that generate predictions for a specific timestamp using databricks inference api. Lambda Python specificities # The python runtime environement is a litle bit special, here is some particularities. 1. Logging # The default logger outputs logs in the Cloudwhatch Logs. Therefor, you can log this way. import logging LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): LOGGER.info(\"Some info\") LOGGER.warning(\"Some warning\") LOGGER.error(\"Some error\") 2. Traceback and errors # Debuging a lambda function can be tricky. Logging the error won't print the traceback. Use the traceback package. import logging import traceback LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): try: your_lambda_logic() ... except Exception as e: LOGGER.error(f\"Something went wrong {e}\") traceback.print_exc() return {\"statusCode\": 500} 3. No requests package # The requests package is not available in AWS runtime. We can use urllib3 instead. import logging import traceback import urllib3 import json LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): try: http = urllib3.PoolManager() get_response = http.request( \"GET\", url=\"...\", headers={}, ) my_data = json.loads(get_response.data) put_response = http.request( \"PUT\", url=\"...\", headers={}, body=json.dumps(my_data), ) if put_response.status != 200: LOGGER.warning(\"Put request failed\") ... except Exception as e: LOGGER.error(f\"Something went wrong {e}\") traceback.print_exc()","title":"Lambda Codes"},{"location":"code/lambdas/#lambda-python-code-examples","text":"You can find all the examples source code files undes 'src/code'. All examples are based on the BrewAI IAQ project. List of examples: Filename Description table_get.py Get endpoint for API Gateway that query items from dynamodb. table_put.py Put endpoint for API Gateway that insert items in dynamodb. manage_conn.py Connections manager for websocket api. msg_conn.py Message sender for websocket api. timestream_get.py Get endpoint for API Gateway that query items from timestream. timestream_put.py Put endpoint for API Gateway that upsert items on timestream. brewai_fetch.py Scheduled lambdas that retreive latest data from api and insert in our own system. make_prediction.py Lambdas that generate predictions for a specific timestamp using databricks inference api.","title":"Lambda Python Code Examples"},{"location":"code/lambdas/#lambda-python-specificities","text":"The python runtime environement is a litle bit special, here is some particularities.","title":"Lambda Python specificities"},{"location":"code/lambdas/#1-logging","text":"The default logger outputs logs in the Cloudwhatch Logs. Therefor, you can log this way. import logging LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): LOGGER.info(\"Some info\") LOGGER.warning(\"Some warning\") LOGGER.error(\"Some error\")","title":"1. Logging"},{"location":"code/lambdas/#2-traceback-and-errors","text":"Debuging a lambda function can be tricky. Logging the error won't print the traceback. Use the traceback package. import logging import traceback LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): try: your_lambda_logic() ... except Exception as e: LOGGER.error(f\"Something went wrong {e}\") traceback.print_exc() return {\"statusCode\": 500}","title":"2. Traceback and errors"},{"location":"code/lambdas/#3-no-requests-package","text":"The requests package is not available in AWS runtime. We can use urllib3 instead. import logging import traceback import urllib3 import json LOGGER = logging.getLogger() LOGGER.setLevel(logging.INFO) def handler(event, context): try: http = urllib3.PoolManager() get_response = http.request( \"GET\", url=\"...\", headers={}, ) my_data = json.loads(get_response.data) put_response = http.request( \"PUT\", url=\"...\", headers={}, body=json.dumps(my_data), ) if put_response.status != 200: LOGGER.warning(\"Put request failed\") ... except Exception as e: LOGGER.error(f\"Something went wrong {e}\") traceback.print_exc()","title":"3. No requests package"},{"location":"modules/api/","text":"API Gateway # Use this module to build an API Gateway for the project. api.RESTApi # Class for the API Gateway. Terraform resources: ApiGatewayRestApi: The REST API. ApiGatewayResource: API resource for the project (/endpoint_name). ApiGatewayResource: /predictions resource. Arguments Name Type Description endpoint_name str Name of the resource for the project api tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description integrations list List of integration on the api api_id str Unique id provided by AWS data_resource_id str Id of the user defined resource pred_resource_id str Id of the predictions resource api_key_value str API key secret value set during finalize() api.RESTApi.add_endpoint # Methode to attach Lambda endpoint to the API. Terraform resources: IamRole: Role for the Lambda. LambdaFunction: The Lambda function. CloudwatchLogGroup: Log group for Lambda Logging (retention 30 days). LambdaPermission: Allow invokation of the lambda from API Gateway. ApiGatewayMethod: Create a method (GET, PUT, etc.) on the endpoint. ApiGatewayIntegration: Attach the Lambda to the method. Argument Type Description http str Http methode (GET, PUT, DELETE, etc.) policies list List of policies arn to attatch to the function filename str Path to the zip file of the lambda environement dict Environement variables to pass to the function timeout int Lambda timeout. Default 5, must be lower than 30 on_prediction bool Whether to attach the endpoint to the /predictions or /endpoint_name Returns: The function arn. api.RESTApi.finalize # Methode to finalize the API. Terraform resources: ApiGatewayDeployment: Deploy the API (make it accessible to the public internet). ApiGatewayStage: An API Stage (version) with name 'v1'. ApiGatewayUsagePlan: A usage plan for the api. No restriction applied on it. ApiGatewayApiKey: An API Key to query the endpoints. ApiGatewayUsagePlanKey: Attach the key to the usage plan. Example # Create an api and attach one lambda to /stockprice/GET: from src.api import RESTApi tags = { \"project\": \"My Project\", \"env\": \"dev\" } myapi = RESTApi( self, \"api\", endpoint_name=\"stockprice\", tags=tags, ) myapi.add_endpoint( http=\"GET\", policies=[database.crud_policy_arn], filename=\"path/to/my/zipfile.zip\", environement={\"DATABASE_NAME\": \"db\", \"TABLE_NAME\": \"stockprice\"}, timeout=20, ) api.finalize()","title":"API Gateway"},{"location":"modules/api/#api-gateway","text":"Use this module to build an API Gateway for the project.","title":"API Gateway"},{"location":"modules/api/#apirestapi","text":"Class for the API Gateway. Terraform resources: ApiGatewayRestApi: The REST API. ApiGatewayResource: API resource for the project (/endpoint_name). ApiGatewayResource: /predictions resource. Arguments Name Type Description endpoint_name str Name of the resource for the project api tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description integrations list List of integration on the api api_id str Unique id provided by AWS data_resource_id str Id of the user defined resource pred_resource_id str Id of the predictions resource api_key_value str API key secret value set during finalize()","title":"api.RESTApi"},{"location":"modules/api/#apirestapiadd_endpoint","text":"Methode to attach Lambda endpoint to the API. Terraform resources: IamRole: Role for the Lambda. LambdaFunction: The Lambda function. CloudwatchLogGroup: Log group for Lambda Logging (retention 30 days). LambdaPermission: Allow invokation of the lambda from API Gateway. ApiGatewayMethod: Create a method (GET, PUT, etc.) on the endpoint. ApiGatewayIntegration: Attach the Lambda to the method. Argument Type Description http str Http methode (GET, PUT, DELETE, etc.) policies list List of policies arn to attatch to the function filename str Path to the zip file of the lambda environement dict Environement variables to pass to the function timeout int Lambda timeout. Default 5, must be lower than 30 on_prediction bool Whether to attach the endpoint to the /predictions or /endpoint_name Returns: The function arn.","title":"api.RESTApi.add_endpoint"},{"location":"modules/api/#apirestapifinalize","text":"Methode to finalize the API. Terraform resources: ApiGatewayDeployment: Deploy the API (make it accessible to the public internet). ApiGatewayStage: An API Stage (version) with name 'v1'. ApiGatewayUsagePlan: A usage plan for the api. No restriction applied on it. ApiGatewayApiKey: An API Key to query the endpoints. ApiGatewayUsagePlanKey: Attach the key to the usage plan.","title":"api.RESTApi.finalize"},{"location":"modules/api/#example","text":"Create an api and attach one lambda to /stockprice/GET: from src.api import RESTApi tags = { \"project\": \"My Project\", \"env\": \"dev\" } myapi = RESTApi( self, \"api\", endpoint_name=\"stockprice\", tags=tags, ) myapi.add_endpoint( http=\"GET\", policies=[database.crud_policy_arn], filename=\"path/to/my/zipfile.zip\", environement={\"DATABASE_NAME\": \"db\", \"TABLE_NAME\": \"stockprice\"}, timeout=20, ) api.finalize()","title":"Example"},{"location":"modules/dynamo/","text":"DynamoDB Table # Use this module to create a dynamo table for the project. dynamo.DynamoDB # Class for the DynamoDB Table. Terraform resources: DynamodbTable: The Dynamo Table. IamPolicy: A policy that allows all CRUD opperation on the table. If isstream is set to true, it will enable DynamoStream and attach a websocket api on the stream. Terraform resources for stream: IamPolicy: A policy to allow stream reading. DynamoWebsocket : The websocket api. Arguments Name Type Description isstream bool Enable or not the dynamo stream tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description table_name str Name of the dynamo table crud_arn str ARN of the CRUD policy streaming.DynamoWebsocket # Resources for websocket API associated to a dynamo table. Terraform resources: DynamodbTable: The table for managing open connections. IamPolicy: Policy for managing connections. Apigatewayv2Api: The Websocket API. IamRole: Role for lambdas. LambdaFunction: Manager and Messager for the API. LambdaPermission: Allow execution from api. CloudwatchLogGroup: Logs for lambdas. Apigatewayv2Integration: API Integration. Apigatewayv2Route: connect and disconnect routes. Apigatewayv2Deployment: API deployement. Apigatewayv2Stage: API version. LambdaEventSourceMapping: Connect lambdas to stream. Argument Type Description stream_arn str The dynamo stream arn stream_policy_arn str The arn to allow readings of the stream tags dict Tags for all resource, must include a 'project' and 'env' key Example # Create a dynamo table with no streams: from src.dynamo import DynamoDB tags = { \"project\": \"My Project\", \"env\": \"dev\" } dynamo = DynamoDB(self, \"dynamo\", isstream=False, tags=tags)","title":"Dynamo Table"},{"location":"modules/dynamo/#dynamodb-table","text":"Use this module to create a dynamo table for the project.","title":"DynamoDB Table"},{"location":"modules/dynamo/#dynamodynamodb","text":"Class for the DynamoDB Table. Terraform resources: DynamodbTable: The Dynamo Table. IamPolicy: A policy that allows all CRUD opperation on the table. If isstream is set to true, it will enable DynamoStream and attach a websocket api on the stream. Terraform resources for stream: IamPolicy: A policy to allow stream reading. DynamoWebsocket : The websocket api. Arguments Name Type Description isstream bool Enable or not the dynamo stream tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description table_name str Name of the dynamo table crud_arn str ARN of the CRUD policy","title":"dynamo.DynamoDB"},{"location":"modules/dynamo/#streamingdynamowebsocket","text":"Resources for websocket API associated to a dynamo table. Terraform resources: DynamodbTable: The table for managing open connections. IamPolicy: Policy for managing connections. Apigatewayv2Api: The Websocket API. IamRole: Role for lambdas. LambdaFunction: Manager and Messager for the API. LambdaPermission: Allow execution from api. CloudwatchLogGroup: Logs for lambdas. Apigatewayv2Integration: API Integration. Apigatewayv2Route: connect and disconnect routes. Apigatewayv2Deployment: API deployement. Apigatewayv2Stage: API version. LambdaEventSourceMapping: Connect lambdas to stream. Argument Type Description stream_arn str The dynamo stream arn stream_policy_arn str The arn to allow readings of the stream tags dict Tags for all resource, must include a 'project' and 'env' key","title":"streaming.DynamoWebsocket"},{"location":"modules/dynamo/#example","text":"Create a dynamo table with no streams: from src.dynamo import DynamoDB tags = { \"project\": \"My Project\", \"env\": \"dev\" } dynamo = DynamoDB(self, \"dynamo\", isstream=False, tags=tags)","title":"Example"},{"location":"modules/lambdas/","text":"Lambdas # Use this module to create lambdas for the project. lambdas.ScheduledLambdas # A lambda function scheduled by event bridge. Terraform resources: IamRole: Role for the lambda. LambdaFunction; The lambda function. CloudwatchLogGroup: Log group for logging. CloudwatchEventRule: Schedule event rule. CloudwatchEventTarget: Attach event rule to the function. LambdaPermission; Allow invokation of the function from CloudWhatch. Arguments Name Type Description name str Name of the lambda function schedule_expression str A valid scheduled expression, ex: 'rate(1 hour)' filename str Path to the zipfile containing lambda code policies list List of policies arn to attach to the function memory_size int Lambda memory size in MB timeout int Timeout of the function environement dict Environement variable to pass to the function tags dict Tags for all resource, must include a 'project' and 'env' key lambdas.InvokableLambdas # A lambda function usable by other services. Terraform resources: IamRole: Role for the lambda. LambdaFunction; The lambda function. CloudwatchLogGroup: Log group for logging. LambdaPermission; Allow invokation of the function from the consumer. Arguments Name Type Description name str Name of the lambda function filename str Path to the zipfile containing lambda code policies list List of policies arn to attach to the function invoke_principal str Principal of the consumer of the lambda (lambda.amazonaws.com, ec2.amazonaws.com, etc.) invoke_from_arn str ARN of the consumer(s) memory_size int Lambda memory size in MB timeout int Timeout of the function environement dict Environement variable to pass to the function tags dict Tags for all resource, must include a 'project' and 'env' key Example # Create a schudled lambda that runs every minute: from src.lambdas import ScheduledLambdas tags = { \"project\": \"My Project\", \"env\": \"dev\" } ScheduledLambdas( self, \"lambda\", name=\"do-something-every-minute\", schedule_expression=\"rate(1 minute)\", filename=\"path/to/my/zipfile.zip\", policies=[read_my_db_policy_arn], memory_size=512, timeout=20, environement={}, tags=tags, ) Create a lambda that can be invoke in any lambda: from src.lambdas import InvokableLambdas InvokableLambdas( self, \"lambda\", name=\"usefull-lambda\", filename=\"path/to/my/zipfile.zip\", policies=[], invoke_principal=\"lambda.amazonaws.com\", invoke_from_arn=\"arn:aws:lambda:region:account-id:function:*\", memory_size=512, timeout=20, environement={}, tags=tags, )","title":"Lambdas"},{"location":"modules/lambdas/#lambdas","text":"Use this module to create lambdas for the project.","title":"Lambdas"},{"location":"modules/lambdas/#lambdasscheduledlambdas","text":"A lambda function scheduled by event bridge. Terraform resources: IamRole: Role for the lambda. LambdaFunction; The lambda function. CloudwatchLogGroup: Log group for logging. CloudwatchEventRule: Schedule event rule. CloudwatchEventTarget: Attach event rule to the function. LambdaPermission; Allow invokation of the function from CloudWhatch. Arguments Name Type Description name str Name of the lambda function schedule_expression str A valid scheduled expression, ex: 'rate(1 hour)' filename str Path to the zipfile containing lambda code policies list List of policies arn to attach to the function memory_size int Lambda memory size in MB timeout int Timeout of the function environement dict Environement variable to pass to the function tags dict Tags for all resource, must include a 'project' and 'env' key","title":"lambdas.ScheduledLambdas"},{"location":"modules/lambdas/#lambdasinvokablelambdas","text":"A lambda function usable by other services. Terraform resources: IamRole: Role for the lambda. LambdaFunction; The lambda function. CloudwatchLogGroup: Log group for logging. LambdaPermission; Allow invokation of the function from the consumer. Arguments Name Type Description name str Name of the lambda function filename str Path to the zipfile containing lambda code policies list List of policies arn to attach to the function invoke_principal str Principal of the consumer of the lambda (lambda.amazonaws.com, ec2.amazonaws.com, etc.) invoke_from_arn str ARN of the consumer(s) memory_size int Lambda memory size in MB timeout int Timeout of the function environement dict Environement variable to pass to the function tags dict Tags for all resource, must include a 'project' and 'env' key","title":"lambdas.InvokableLambdas"},{"location":"modules/lambdas/#example","text":"Create a schudled lambda that runs every minute: from src.lambdas import ScheduledLambdas tags = { \"project\": \"My Project\", \"env\": \"dev\" } ScheduledLambdas( self, \"lambda\", name=\"do-something-every-minute\", schedule_expression=\"rate(1 minute)\", filename=\"path/to/my/zipfile.zip\", policies=[read_my_db_policy_arn], memory_size=512, timeout=20, environement={}, tags=tags, ) Create a lambda that can be invoke in any lambda: from src.lambdas import InvokableLambdas InvokableLambdas( self, \"lambda\", name=\"usefull-lambda\", filename=\"path/to/my/zipfile.zip\", policies=[], invoke_principal=\"lambda.amazonaws.com\", invoke_from_arn=\"arn:aws:lambda:region:account-id:function:*\", memory_size=512, timeout=20, environement={}, tags=tags, )","title":"Example"},{"location":"modules/timestream/","text":"Timestream database # Use this module to create a timestream database and table for the project. timestream.Timestream # Class for the Timestream Database and Table. Terraform resources: TimestreamwriteDatabase: The database. TimestreamwriteTable: The table. Retention periods are set to 1 day of in-memory and 30 days of magnetic store. IamPolicy: Policy that grant permission for CRUD opperation on table. Arguments Name Type Description table_name str Name of the timestream table tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description crud_arn str ARN of the CRUD Policy db_name str Name of the project database table_name str Name of the project table Example # Create a timestream database and table: from src.timestream import Timestream tags = { \"project\": \"My Project\", \"env\": \"dev\" } table = Timestream(self, \"timestram-id\", \"my_table\", tags=tags)","title":"Timestream"},{"location":"modules/timestream/#timestream-database","text":"Use this module to create a timestream database and table for the project.","title":"Timestream database"},{"location":"modules/timestream/#timestreamtimestream","text":"Class for the Timestream Database and Table. Terraform resources: TimestreamwriteDatabase: The database. TimestreamwriteTable: The table. Retention periods are set to 1 day of in-memory and 30 days of magnetic store. IamPolicy: Policy that grant permission for CRUD opperation on table. Arguments Name Type Description table_name str Name of the timestream table tags dict Tags for all resource, must include a 'project' and 'env' key Attributes Name Type Description crud_arn str ARN of the CRUD Policy db_name str Name of the project database table_name str Name of the project table","title":"timestream.Timestream"},{"location":"modules/timestream/#example","text":"Create a timestream database and table: from src.timestream import Timestream tags = { \"project\": \"My Project\", \"env\": \"dev\" } table = Timestream(self, \"timestram-id\", \"my_table\", tags=tags)","title":"Example"}]}